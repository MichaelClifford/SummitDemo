{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.animation as animation\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import glob\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "from IPython import display\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_LOC = '../HMPDataset/'\n",
    "activity_list = [i for i in glob.glob(f'{IMAGE_LOC}/*') if i.find('_') > 0 and \"MODEL\" not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(activity_list):\n",
    "    '''Read files in each activity in activity_list\n",
    "    Returns dict: key = activity name -> array of numpy arrays of shape (n_observations, 3) = (ax,ay,az)\n",
    "    '''\n",
    "    data = {}\n",
    "    \n",
    "    for t in activity_list: #loop over each activity type\n",
    "        activity_name = t.split('/')[-1]\n",
    "        data[activity_name] = []\n",
    "    \n",
    "        filenames = glob.glob(t + '/*')\n",
    "        \n",
    "        for f in filenames: #loop over every participants time-series\n",
    "            df = pd.read_csv(f, sep=' ', header=None)\n",
    "            \n",
    "            #ts = np.sqrt((df**2).sum(axis=1)) #magnitude of acceleration vector\n",
    "            \n",
    "            data[activity_name].append(np.array(df))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_acceleration_timeseries(data):\n",
    "    '''Input: data returned by read_data\n",
    "    Output: dictionary mapping activity name -> list of single time-series of acceleration magnitudes\n",
    "    '''\n",
    "    \n",
    "    data_ts = {}\n",
    "    \n",
    "    for k in data:\n",
    "        data_ts[k] = []\n",
    "        \n",
    "        for sample in data[k]: #(ax, ay, az)\n",
    "            data_ts[k].append(np.sqrt((sample**2).sum(axis=1)))\n",
    "    \n",
    "    return data_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(activity_list)\n",
    "data_ts = get_acceleration_timeseries(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_stats(params):\n",
    "    ts = params[0]\n",
    "    label = params[1]\n",
    "    bins = params[2]\n",
    "    #basic statistical measures\n",
    "    mean = np.mean(ts)\n",
    "    median = np.median(ts)\n",
    "    std = np.std(ts)\n",
    "    length = len(ts)\n",
    "    kurtosis = scipy.stats.kurtosis(ts)\n",
    "    \n",
    "    n,b,p = plt.hist(ts, bins=bins)\n",
    "    n = np.array(n)/float(np.sum(n)) #normalize i.e. fraction of entries in each bin\n",
    "    \n",
    "    if median == 0: \n",
    "        features = {'mean_over_median': 0, #dimensionless            \n",
    "                    'std_over_median': 0, #dimensionless            \n",
    "                    'length': length,\n",
    "                    'kurtosis': kurtosis, #already dimensionless by definition\n",
    "                   }\n",
    "        \n",
    "    else: \n",
    "        features = {'mean_over_median': mean/median, #dimensionless            \n",
    "            'std_over_median': std/median, #dimensionless            \n",
    "            'length': length,\n",
    "            'kurtosis': kurtosis, #already dimensionless by definition\n",
    "           }\n",
    "        \n",
    "    for i, val in enumerate(n):\n",
    "        features[f'binfrac_{i}'] = val\n",
    "    \n",
    "    features['label'] = label\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0,100,10)\n",
    "data_params = []\n",
    "for k in data_ts:\n",
    "    for elem in data_ts[k]:\n",
    "        data_params.append((elem,k,bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03202709356943766 minutes\n"
     ]
    }
   ],
   "source": [
    "then = time.time()\n",
    "pool = mp.Pool(processes=8)\n",
    "results = pool.map(featurize_stats,data_params)\n",
    "print((time.time()-then)/60, \"minutes\")\n",
    "pool.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcliffor/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(results) \n",
    "train_df, test_df = train_test_split(results, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = np.array(train_df['label'])\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoder = label_encoder.fit_transform(one_hot)\n",
    "one_hot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "integer_encoder = integer_encoder.reshape(len(integer_encoder),1)\n",
    "train_label = one_hot_encoder.fit_transform(integer_encoder)\n",
    "\n",
    "one_hot = np.array(test_df['label'])\n",
    "#label_encoder = LabelEncoder()\n",
    "integer_encoder = label_encoder.transform(one_hot)\n",
    "#one_hot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "integer_encoder = integer_encoder.reshape(len(integer_encoder),1)\n",
    "test_label = one_hot_encoder.transform(integer_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(13,)),\n",
    "    keras.layers.Dense(14, activation=tf.nn.log_softmax)\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "h  = []\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: h.append(model.layers[0].get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm = tf.train.AdamOptimizer(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adm, \n",
    "              loss=tf.losses.softmax_cross_entropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit( train_df.drop('label', axis=1), train_label, epochs=8001, batch_size=100, verbose=0, callbacks=[print_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "use('TKAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "fig.show()\n",
    "\n",
    "for ii in range(len(h)):\n",
    "    if ii%100 == 0 or (ii < 100 and ii%10 == 0):\n",
    "        im = h[ii][0]\n",
    "        plt.imshow(im)\n",
    "        ax.set_title(\"epoch: \"+str(ii))\n",
    "        fig.canvas.draw()\n",
    "        sleep(0.5)\n",
    "        ax.cla()\n",
    "\n",
    "im = h[ii][0]\n",
    "plt.imshow(im)\n",
    "ax.set_title(ii)\n",
    "fig.canvas.draw()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(3)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(history.history['acc'], label = 'train_accuracy',)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_df.drop('label', axis=1), test_label)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added code snippet from https://www.tensorflow.org/serving/tutorials/Serving_REST_simple\n",
    "# to save model for TF-serving\n",
    "\n",
    "save = False\n",
    "\n",
    "if save == True:\n",
    "    MODEL_DIR = \"models/\"\n",
    "    version = 1\n",
    "    export_path = os.path.join(MODEL_DIR, str(version))\n",
    "    print('export_path = {}\\n'.format(export_path))\n",
    "    if os.path.isdir(export_path):\n",
    "        print('\\nAlready saved a model, cleaning up\\n')\n",
    "        !rm -r {export_path}\n",
    "\n",
    "    tf.saved_model.simple_save(\n",
    "        keras.backend.get_session(),\n",
    "        export_path,\n",
    "        inputs={'input_data': model.input},\n",
    "        outputs={t.name:t for t in model.outputs})\n",
    "\n",
    "    print('\\nSaved model:')\n",
    "    !ls -l {export_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = history.history['acc']\n",
    "# x = sorted_sample\n",
    "# t = np.linspace(1,len(x),len(x))\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.axis([0,len(x),0,1])\n",
    "# l, = ax.plot([],[])\n",
    "\n",
    "# def animate(i):\n",
    "#     l.set_data(t[:i], x[:i])\n",
    "\n",
    "# ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(x), interval = 20)\n",
    "\n",
    "# from IPython.display import HTML\n",
    "# HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = [[plt.imshow(h[i][0],animated=True)] for i in range(len(h))]\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ani = animation.ArtistAnimation(fig,j, interval=50,blit=True, repeat_delay = 1000)\n",
    "# ani.save(\"tep.gif\", writer='imagemagick', fps=1)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# sample_size = 200\n",
    "# sorted_sample = [\n",
    "#     x[i] for i in sorted(random.sample(range(len(x)), sample_size))\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from matplotlib import cm\n",
    "# j = [Image.fromarray(np.uint8(cm.gist_earth(h[i][0]))) for i in range(len(h))]\n",
    "\n",
    "# j[0].save(\"out.gif\",save_all=True, append_image=j[1:], duration=100)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 429,
   "position": {
    "height": "40px",
    "left": "21px",
    "right": "20px",
    "top": "58px",
    "width": "706px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
