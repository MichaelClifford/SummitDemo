{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Gesture Data from S3 and Preprocess & Backup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)  Read Data from S3 and convert input data to featurized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path_to_data,fs):\n",
    "    \n",
    "    Data = []\n",
    "    \n",
    "    for gesture in list_of_gesture_paths:\n",
    "        single_gesture_data = featurize_one_gesture(gesture,fs)\n",
    "        Data = Data + single_gesture_data\n",
    "    \n",
    "    return Data\n",
    "\n",
    "def mp_get_data(path_to_data,fs):\n",
    "    \n",
    "    Data = []\n",
    "    data_params = []\n",
    "    \n",
    "    for gesture in list_of_gesture_paths:\n",
    "        data_params.append((gesture,fs))\n",
    "\n",
    "    pool = mp.Pool(processes=8)\n",
    "    Data = pool.map(featurize_one_gesture, data_params)\n",
    "    \n",
    "    Data = [i for gestures in Data for i in gestures]\n",
    "    \n",
    "    return Data\n",
    "\n",
    "def featurize_one_gesture(params):\n",
    "    gesture_path = params[0]\n",
    "    fs = params[1]\n",
    "    \n",
    "    current_gesture_data = read_gesture_data(fs, gesture_path)\n",
    "    label = current_gesture_data[\"gesture\"][0]\n",
    "    data = []\n",
    "    \n",
    "    for i in range(len(current_gesture_data)):\n",
    "        data.append(get_acceleration_data(current_gesture_data,i,label))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_acceleration_data(current_gesture_data, row_index, label):\n",
    "    \n",
    "    acceleration = [i[0:3] for i in current_gesture_data.iloc[row_index].motion]\n",
    "    acceleration = pd.DataFrame(acceleration)\n",
    "    features = get_accleration_timeseries(acceleration)\n",
    "    params = [features, label, np.arange(0,100,10)]\n",
    "    features = featurize(params)\n",
    "    return features\n",
    "\n",
    "\n",
    "def read_gesture_data(fs,gesture_path):\n",
    "    \n",
    "    examples = []\n",
    "    files = fs.ls(gesture_path)\n",
    "    for file in files:\n",
    "        with fs.open(file) as f:\n",
    "            opened_file = json.loads(f.read())\n",
    "        \n",
    "        examples.append(opened_file)\n",
    "    \n",
    "    examples = pd.io.json.json_normalize(examples)\n",
    "    \n",
    "    return examples \n",
    "\n",
    "def featurize(params):\n",
    "    \n",
    "    ts = params[0]\n",
    "    label = params[1]\n",
    "    bins = params[2]\n",
    "    mean = np.mean(ts)\n",
    "    median = np.median(ts)\n",
    "    std = np.std(ts)\n",
    "    length = len(ts)\n",
    "    kurtosis = scipy.stats.kurtosis(ts)\n",
    "    \n",
    "    n,b,p = plt.hist(ts, bins=bins)\n",
    "    n = np.array(n)/float(np.sum(n)) #normalize i.e. fraction of entries in each bin\n",
    "    \n",
    "    if median == 0: \n",
    "        features = {'mean_over_median': 0, #dimensionless            \n",
    "                    'std_over_median': 0, #dimensionless            \n",
    "                    'length': length,\n",
    "                    'kurtosis': kurtosis, #already dimensionless by definition\n",
    "                   }\n",
    "        \n",
    "    else: \n",
    "        features = {'mean_over_median': mean/median, #dimensionless            \n",
    "            'std_over_median': std/median, #dimensionless            \n",
    "            'length': length,\n",
    "            'kurtosis': kurtosis, #already dimensionless by definition\n",
    "           }\n",
    "        \n",
    "    for i, val in enumerate(n):\n",
    "        features[f'binfrac_{i}'] = val\n",
    "    \n",
    "    features['label'] = label\n",
    "    \n",
    "    return features\n",
    "    \n",
    "def get_accleration_timeseries(timeseries):\n",
    "    \n",
    "    timeseries = timeseries.apply((lambda x: x**2))\n",
    "    timeseries = timeseries.sum(axis=1)\n",
    "    timeseries = timeseries.apply(np.sqrt)\n",
    "    \n",
    "    return timeseries # 1xn Series  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"cchase-rh-demo-4/training-data\"\n",
    "fs = s3fs.S3FileSystem()\n",
    "list_of_gesture_paths = fs.ls(path_to_data)\n",
    "Data = mp_get_data(list_of_gesture_paths,fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_over_median': 0.9235905810889316,\n",
       " 'std_over_median': 0.6093665285469015,\n",
       " 'length': 318,\n",
       " 'kurtosis': -0.08115848043356833,\n",
       " 'binfrac_0': 0.889937106918239,\n",
       " 'binfrac_1': 0.1069182389937107,\n",
       " 'binfrac_2': 0.0031446540880503146,\n",
       " 'binfrac_3': 0.0,\n",
       " 'binfrac_4': 0.0,\n",
       " 'binfrac_5': 0.0,\n",
       " 'binfrac_6': 0.0,\n",
       " 'binfrac_7': 0.0,\n",
       " 'binfrac_8': 0.0,\n",
       " 'label': 'shake'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data from S3 and Backup locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_up_s3_to_local(path_on_s3, path_local, fs):\n",
    "    # check is directory exists locally\n",
    "    if path_local not in os.listdir():\n",
    "        os.mkdir(path_local)\n",
    "    \n",
    "    files = fs.walk(path_to_data)\n",
    "    \n",
    "    for f in files:\n",
    "        f_name = f.replace(\"/\",\"-\")\n",
    "        if f_name not in os.listdir(path_local):\n",
    "            with fs.open(f) as h:\n",
    "                opened_file = json.loads(h.read())\n",
    "                \n",
    "            with open(path_local+\"/\"+f_name, 'w') as g:\n",
    "                json.dump(opened_file, g, ensure_ascii=False)\n",
    "        else:\n",
    "            print(f_name, \"already in Dataset\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cchase-rh-demo-4-training-data-draw-circle-1551880300361-58abd56f-65b5-495d-9ad4-6ac50f99f7fc already in Dataset\n"
     ]
    }
   ],
   "source": [
    "back_up_s3_to_local(path_to_data, \"training-data\", fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
